{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47eTBHYNP4g1"
      },
      "source": [
        "# Introduction to LCEL and LangGraph: LangChain Powered RAG\n",
        "\n",
        "In the following notebook we're going to focus on learning how to navigate and build useful applications using LangChain, specifically LCEL, and how to integrate different APIs together into a coherent RAG application!\n",
        "\n",
        "In the notebook, you'll complete the following Tasks:\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  1. Install LangGraph\n",
        "  2. Understanding States and Nodes\n",
        "  3. Building a Basic Graph\n",
        "  4. Implementing a Simple RAG Graph\n",
        "  5. Extending the Graph with Complex Flows\n",
        "\n",
        "Let's get started!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ayVXHXHRE_t"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHd6POM0JFN"
      },
      "source": [
        "## Installing Required Libraries\n",
        "\n",
        "We'll start by grabbing all of our LangChain related packages!\n",
        "\n",
        "> NOTE: DO NOT RUN THIS CELL IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCC2AR-Q0m0x",
        "outputId": "cbd49ab6-f2fb-420c-e64c-e656ad21524e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'langgraph>=0.5.0,'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#!pip install -qU \"langgraph>=0.5.0\", \"langsmith>=0.4.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6wTp9C5qbY"
      },
      "source": [
        "## Set Environment Variables\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs - so we'll set our `OPENAI_API_KEY` `env` variable here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pKAfycq73wE",
        "outputId": "0b5702c2-028b-4bf4-ae8a-fffe243574a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsujAkpRWpJ"
      },
      "source": [
        "### A Note On Runnables\n",
        "\n",
        "# Understanding LangChain Runnables and LCEL\n",
        "\n",
        "In LangChain, a Runnable is like a LEGO brick in your AI application - it's a standardized component that can be easily connected with other components. The real power of Runnables comes from their ability to be combined in flexible ways using LCEL (LangChain Expression Language).\n",
        "\n",
        "## Key Features of Runnables\n",
        "\n",
        "### 1. Universal Interface\n",
        "Every Runnable in LangChain follows the same pattern:\n",
        "- Takes an input\n",
        "- Performs some operation\n",
        "- Returns an output\n",
        "\n",
        "This consistency means you can treat different components (like models, retrievers, or parsers) in the same way.\n",
        "\n",
        "### 2. Built-in Parallelization\n",
        "Runnables come with methods for handling multiple inputs efficiently:\n",
        "```python\n",
        "# Process inputs in parallel, maintain order\n",
        "results = chain.batch([input1, input2, input3])\n",
        "\n",
        "# Process inputs as they complete\n",
        "for result in chain.batch_as_completed([input1, input2, input3]):\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "### 3. Streaming Support\n",
        "Perfect for responsive applications:\n",
        "```python\n",
        "# Stream outputs as they're generated\n",
        "for chunk in chain.stream({\"query\": \"Tell me a story\"}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "```\n",
        "\n",
        "### 4. Easy Composition\n",
        "The `|` operator makes building pipelines intuitive:\n",
        "```python\n",
        "# Create a basic RAG chain\n",
        "rag_chain = retriever | prompt | model | output_parser\n",
        "```\n",
        "\n",
        "## Common Types of Runnables\n",
        "\n",
        "- **Language Models**: Like our `ChatOpenAI` instance\n",
        "- **Prompt Templates**: Format inputs consistently\n",
        "- **Retrievers**: Get relevant context from a vector store\n",
        "- **Output Parsers**: Structure model outputs\n",
        "- **LangGraph Nodes**: Individual components in our graph\n",
        "\n",
        "Think of Runnables as the building blocks of your LLM application. Just like how you can combine LEGO bricks in countless ways, you can mix and match Runnables to create increasingly sophisticated applications!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaVlJiilDzwM"
      },
      "source": [
        "## LangGraph Based RAG\n",
        "\n",
        "Now that we have a reasonable grasp of LCEL and the idea of Runnables - let's see how we can use LangGraph to build the same system!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77-NKo1EowG"
      },
      "source": [
        "### Primer: What is LangGraph?\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "#### Why Cycles?\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "#### Why LangGraph?\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!\n",
        "\n",
        "> NOTE: We're going to focus on building a simple DAG for today's assignment as an introduction to LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfLCnMXNE_Qc"
      },
      "source": [
        "### Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "> coordinated multi-actor and stateful applications\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "However, in our example here, we're focusing on a simpler `State` object:\n",
        "\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: list[Document]\n",
        "    response: str\n",
        "```\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. **We initialize our state object**:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "2. **Our user submits a query to our application.**  \n",
        "   We store the user's question in `state[\"question\"]`. Now we have:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **We pass our state object to an Agent node** which is able to read the current state. It will use the value of `state[\"question\"]` as input and might retrieve some context documents related to the question. It then generates a response which it stores in `state[\"response\"]`. For example:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [Document(page_content=\"...some data...\")],\n",
        "       \"response\": \"The Eiffel Tower is about 324 meters tall...\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "That's it! The important part is that we have a consistent object (`State`) that's passed around, holding the crucial information as we go from one node to the next. This ensures our application has a single source of truth about what has happened so far and what is happening now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kxczzsfVFNWT"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: list[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6xFY0_HoXG"
      },
      "source": [
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL Runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keL9O1drInw1"
      },
      "source": [
        "### Building Nodes\n",
        "\n",
        "We're going to need two nodes:\n",
        "\n",
        "A node for retrieval, and a node for generation.\n",
        "\n",
        "Let's start with our `retrieve` node!\n",
        "\n",
        "Notice how we do not need to update the state object in the node, but can instead return a modification directly to our state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Building a Retriever with LangChain\n",
        "\n",
        "In order to build our `retrieve` node, we'll first need to build a retriever!\n",
        "\n",
        "This will involve the following steps: \n",
        "\n",
        "1. Ingesting Data\n",
        "2. Chunking the Data\n",
        "3. Vectorizing the Data and Storing it in a Vector Database\n",
        "4. Converting it to a Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Retreiver Step 1: Ingesting Data\n",
        "\n",
        "In today's lesson, we're going to be building a RAG system to answer questions about loan complaints - and we will pull information into our index (vectorized chunks stored in our vector store) through LangChain's [`CSVLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> NOTE: We'll be using an async loader during our document ingesting - but our Jupyter Kernel is already running in an asyc loop! This means we'll want the ability to *nest* async loops. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we're good to load our documents through the [`PyMuPDFLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "\n",
        "loan_knowledge_resources = directory_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Volume 3\\nAcademic Calendars, Cost of Attendance, and\\nPackaging\\nIntroduction\\nThis volume of the Federal Student Aid (FSA) Handbook discusses the academic calendar, payment period, and\\ndisbursement requirements for awarding aid under the Title IV student financial aid programs, determining a student9s\\ncost of attendance, and packaging Title IV aid.\\nThroughout this volume of the Handbook, the words \"we,\" \"our,\" and \"us\" refer to the United States Department of\\nEducation (the Department). The word \"you\" refers to the primary audience of the Handbook, school financial aid\\nadministrators. In other volumes of the Handbook we use \"institution,\" \"school,\" and \"college\" interchangeably, unless a\\nmore specific meaning is provided. In this volume we consistently use the term \"school.\" <HEA= refers to the Higher\\nEducation Act of 1965, as amended. Title IV refers to the student financial aid programs authorized under Title IV of the\\nHEA.\\nWe appreciate any comments that you have on this volume as wel'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_knowledge_resources[0].page_content[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TextSplitting aka Chunking\n",
        "\n",
        "We'll use the `RecursiveCharacterTextSplitter` to create our toy example.\n",
        "\n",
        "It will split based on the following rules:\n",
        "\n",
        "- Each chunk has a maximum size of 1000 tokens\n",
        "- It will try and split first on the `\\n\\n` character, then on the `\\n`, then on the `<SPACE>` character, and finally it will split on individual tokens.\n",
        "\n",
        "Let's implement it and see the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "loan_knowledge_chunks = text_splitter.split_documents(loan_knowledge_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 🏗️ Activity #1:\n",
        "\n",
        "While there's nothing specifically wrong with the chunking method used above - it is a naive approach that is not sensitive to specific data formats.\n",
        "\n",
        "Brainstorm some ideas that would split large single documents into smaller documents.\n",
        "\n",
        "1. `YOUR IDEA HERE`\n",
        "2. `YOUR IDEA HERE`\n",
        "3. `YOUR IDEA HERE`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "1. We can split the text into paragraphs. It's a reasonable assumption that sentences within a single paragraphs share a similar context.\n",
        "2.  We can split the text into sentences, calculate an embedding per sentence, and then compare the similarity of the sentences. We could then define a similarity threshold and group consecutive sentences based on their similarities scores.\n",
        "3. Similar approach than #2, but we use a clustering algorithm to group sentences that have a similar context based on their embedding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Embeddings and Dense Vector Search\n",
        "\n",
        "Now that we have our individual chunks, we need a system to correctly select the relevant pieces of information to answer our query.\n",
        "\n",
        "This sounds like a perfect job for embeddings!\n",
        "\n",
        "We'll be using OpenAI's `text-embedding-3` model as our embedding model today!\n",
        "\n",
        "Let's load it up through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "What is the embedding dimension, given that we're using `text-embedding-3-small`?\n",
        "\n",
        "You will need to fill the next cell out correctly with your embedding dimension for the rest of the notebook to run.\n",
        "\n",
        "> HINT: Check out the docs to help you answer this question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 1536 # YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Using A Vector Database - Intoduction to Qdrant\n",
        "\n",
        "Up to this point, we've been using a dictionary to hold our embeddings - typically, we'll want to use a more robust strategy.\n",
        "\n",
        "In this bootcamp - we'll be focusing on leveraging [Qdrant's vector database](https://qdrant.tech/qdrant-vector-database/).\n",
        "\n",
        "Let's take a look at how we set-up Qdrant!\n",
        "\n",
        "> NOTE: We'll be spending a lot of time learning about Qdrant throughout the remainder of our time together - but for an initial primer, please check out [this resource](https://qdrant.tech/articles/what-is-a-vector-database/)\n",
        "\n",
        "We are going to be using an \"in-memory\" Qdrant client, which means that our vectors will be held in our system's memory (RAM) - this is useful for prototyping and developement at smaller scales - but would need to be modified when moving to production. Luckily for us, this modification is trivial!\n",
        "\n",
        "> NOTE: While LangChain uses the terminology \"VectorStore\" (also known as a Vector Library), Qdrant is a \"Vector Database\" - more info. on that [here.](https://weaviate.io/blog/vector-library-vs-vector-database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to create a collection - a collection is a specific...collection of vectors within the Qdrant client.\n",
        "\n",
        "These are useful as they allow us to create multiple different \"warehouses\" in a single client, which can be leveraged for personalization and more!\n",
        "\n",
        "Also notice that we define what our vector shapes are (embedding dim) as well as our desired distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can assemble our vector database! Notice that we provide our client, our created collection, and our embedding model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    embedding=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our vector database set-up, we can add our documents into it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=loan_knowledge_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "Now that we have an idea of how we're getting our most relevant information - let's see how we could create a pipeline that would automatically extract the closest chunk to our query and use it as context for our prompt!\n",
        "\n",
        "This will involve a popular LangChain interace known as `as_retriever`!\n",
        "\n",
        "> NOTE: We can still specify how many documents we wish to retrieve per vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 25, '_id': '13bf7bef28204da5b750f474123aca0c', '_collection_name': 'loan_knowledge_index'}, page_content='hour, or non-SE9W nonstandard term program is offered in modules, the minimum loan period is still the lesser of the\\nacademic year or the program length (or remaining portion of the program).\\nFor Title IV aid purposes, students are allowed to skip one or more modules. However, if a loan period includes modules\\nthat the student does not attend, the COA for the loan period may not include costs associated with those modules.\\nMinimum Loan Period: Standard Term Combined With an Intersession\\nAs we explain under <Intersessions= in Volume 3, Chapter 1, in limited cases for academic programs offered in standard\\nterms, a short nonstandard term (often called an <intersession=) may be combined with a preceding or following standard\\nterm and considered to be a single standard term. In such cases, the minimum loan period for a Direct Loan is different\\ndepending on whether a student attends the intersession. If a student who attends the intersession requests a loan for the\\ncombined term, the loan period includes the standard term plus the intersession. However, if the student attends only the\\nstandard term and is not enrolled in the intersession that is attached to that term, the loan period includes only the\\nstandard term.\\nMaximum Loan Periods\\nThe maximum period for which you may originate a Direct Loan is generally an academic year. However, if your school\\napplies the annual loan limit for Direct Subsidized Loans and Direct Unsubsidized Loans to a period of time greater than\\nan academic year, you may originate a Direct Loan for that longer period of time. For example, a school might offer an\\n1100 clock-hour program and define the academic year as 900 clock hours but could choose to allow students to receive\\njust one annual loan limit for the entire 1100-hour program. In that case, the loan period would correspond to the length\\nof the program, a period of time that is longer than the academic year.\\nDirect Loan Disbursement Requirements\\nFor general guidance on the timing of disbursements made under the Title IV programs, see Volume 3, Chapter 1. For\\nguidance on reporting Title IV program disbursements through the COD System and the rules for making early\\ndisbursements, late disbursements, and retroactive payments, see Volume 4, Chapter 2. In this section we discuss certain\\nother disbursement requirements that are specific to the Direct Loan Program.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal Direct Loan disbursement\\nrequirements that apply when periods of clinical work are included in a standard term.\\nRequirement for Substantially Equal Disbursements\\nDirect Loans must be disbursed in substantially equal installments, regardless of any difference in costs for different\\npayment periods that are within the same loan period, and no Direct Loan disbursement may exceed one-half of the loan\\nMaximum Loan Period\\n34 CFR 685.301(a)(10)(iv)\\nDetermining Direct Loan Disbursement Dates and Amounts\\n34 CFR 685.303(d)'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 23, '_id': '322a56ff44074b22bdf3aa28c06fe69a', '_collection_name': 'loan_knowledge_index'}, page_content='period are separated by one or more terms in which the student is ineligible. For example, if a student is expected to be\\nenrolled on at least a half-time basis in the fall and spring quarters of an academic year consisting of the fall, winter, and\\nspring quarters, but the student indicates that they do not plan to attend the winter quarter (or that they plan to be\\nenrolled on a less than half-time basis during that quarter), the school may still originate a loan for a loan period covering\\nthe fall, winter, and spring quarters. Of course, no costs associated with winter quarter may be included in the student9s\\nCOA when determining the loan amount the student is eligible to receive for the fall and spring quarters. Similarly, if a\\nschool initially originates a loan for a fall-winter-spring loan period based on a student9s anticipated enrollment status of\\nat least half time during all three quarters, but the student subsequently does not attend the winter quarter or temporarily\\ndrops below half-time status for that term, and then resumes at least half-time enrollment in the spring, the school is not\\nrequired to make any changes to the original fall-winter-spring loan period. However, it may be necessary for the school\\nto adjust the originally approved loan amount if that amount is no longer supported by the reduced costs for the fall and\\nspring quarters only.\\nIn the first scenario described above the school could also choose to originate two separate loans for fall-only and spring-\\nonly loan periods. In the second scenario the school would also have the option of adjusting the original fall-winter-spring\\nloan period to fall-only, and then originating a new spring-only loan. Note, however, that in both cases the school would\\nthen be required to separately subtract the student9s full SAI from the fall-only and spring-only costs when determining\\nthe student9s Direct Subsidized Loan eligibility for those terms (see <No Alternate SAI When Originating Loans for Periods\\nOther Than Nine Months= earlier in this chapter). In some cases this could significantly reduce or even eliminate a\\nstudent9s need for Direct Subsidized Loans. In contrast, using a fall-winter-spring loan period (excluding all costs\\nassociated with the winter quarter) would allow the school to subtract the full SAI from the higher combined costs for the\\nfall and spring terms, partially mitigating the effect of not having alternate SAIs for periods of enrollment other than nine\\nmonths.\\nThe limited exception described above applies only if a student is eligible to receive a Direct Loan during the first and last\\nterms within the loan period. The term in which the student is ineligible cannot be the first or last term in the loan period.\\nFor instance, a school may not originate a loan for a fall-winter-spring loan period if the student does not attend the fall\\nterm or the spring term.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal loan period rules that apply when\\nperiods of clinical work are included in a standard term.\\nMinimum Loan Periods\\nThe minimum period for which a school may originate a Direct Loan varies depending on the school9s academic calendar.\\nAs explained below and in Chapter 7, different rules apply for purposes of determining the minimum loan period for a\\nDirect Loan and the type of academic year that a school may use to monitor Direct Loan annual loan limits depending on\\nwhether a program is term-based (including subscription-based programs; see Volume 3, Chapter 1) with either standard'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 22, '_id': 'c7374095f3004d7daf66f31c8bf48b35', '_collection_name': 'loan_knowledge_index'}, page_content=\"or to prevent the total aid package from exceeding the student9s need.\\nAlthough a school isn9t required to return Direct Loan funds that were disbursed to the borrower (either directly or by\\napplying them to the student's account) before the overaward situation occurred, the law doesn9t prevent your school\\nfrom returning funds that were applied to the student account if you choose to do so. A borrower who receives a direct\\npayment of loan funds is not required to repay an overawarded amount, unless the overaward was caused by the\\nborrower9s misreporting or withholding of information.\\nLoan Periods\\nThe loan period (also referred to as the <period of enrollment=) is the period for which a Direct Loan is intended. It must\\ncoincide with an academic period established by the school for which institutional charges are generally assessed (e.g.,\\nsemester, trimester, quarter, length of the student9s program, or academic year). It9s important to define the loan period\\nat the beginning of the loan awarding process, because the timing and amount of Direct Loan disbursements are tied to\\nthe loan period.\\nGenerally, the loan period may not include terms in which a student is ineligible (for example, if the student is not enrolled\\nduring a particular term or is enrolled less than half time during a term). There is a limited exception to this rule if the loan\\nperiod begins and ends with a term in which the student is eligible for Direct Loans, but the first and last terms of the loan\"),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 24, '_id': '1542785dd289438f9200fee149a0262a', '_collection_name': 'loan_knowledge_index'}, page_content='2. \\nNonstandard terms that are substantially equal, but one or more of the terms in the academic year\\ncontains fewer than nine weeks.\\nNon-\\nSE9W\\n3. \\nNonstandard terms that are not substantially equal in length (one or more of the terms in the academic\\nyear differs in length from another term by more than two weeks).\\nNon-\\nSE9W\\nWe refer to the first type of nonstandard term as <SE9W= nonstandard terms. We group the second and third types\\ntogether and refer to them as <non-SE9W= nonstandard terms.\\nPrograms with SE9W nonstandard terms are treated the same as standard-term programs for purposes of determining\\nminimum loan period length and monitoring annual loan limits. However, programs with non-SE9W nonstandard terms are\\ntreated the same as non-term programs for these purposes.\\nNote that substantially equal nonstandard terms (the first two types of nonstandard terms described above) are treated\\ndifferently for purposes of determining Direct Loan payment periods than for determining minimum loan period length\\nand monitoring annual loan limits. As explained in Volume 1, Chapter 1, if a program is offered in standard terms or in\\nnonstandard terms that are substantially equal in length (regardless of the length of the nonstandard term), the payment\\nperiod is the term.\\nHowever, for purposes of determining the minimum loan period for a Direct Loan and monitoring Direct Loan annual loan\\nlimits, substantially equal nonstandard terms that contain fewer than nine weeks are treated the same as nonstandard\\nterms that are not substantially equal. This means that if a program has substantially equal nonstandard terms that are\\nless than nine weeks in length, you must make a Direct Loan disbursement each term (the same as would be the case if\\nthe program were offered in standard terms), but the minimum loan period and the type of academic year used to\\nmonitor Direct Loan annual loan limits must be determined in accordance with the rules that apply to non-term programs.\\nFor detailed information on standard term, nonstandard term, and non-term programs, see Volume 1, Chapter 1.\\nMinimum Loan Period: Standard Term and SE9W Nonstandard Term Programs\\nFor credit-hour programs with standard terms (semesters, quarters, or trimesters), or with SE9W\\nnonstandard terms, the minimum loan period is a single academic term. For example, if a student will be enrolled in the\\nfall semester only and will skip the spring semester, you may originate a loan with a loan period that covers only the fall\\nterm.\\nMinimum Loan Period: Clock-Hour, Non-Term, and Non-SE9W Nonstandard Term Programs\\nFor all other programs (i.e., clock-hour, non-term, and non-SE9W nonstandard term programs), the minimum\\nloan period is generally the lesser of the program length (or remainder of the program, if there is less than full academic\\nyear remaining) or the academic year. There are exceptions to this minimum loan period rule when originating loans for\\ntransfer students, or for students who complete or otherwise cease enrollment in one program and then begin a different\\nprogram at the same school. We discuss these exceptions in detail in Chapter 7 of this volume.\\nMinimum Loan Period: Programs Offered in Modules\\nIf a program is offered in modules, this does not change the minimum loan period rules for Direct Loans. For example, if a\\nstandard or SE9W nonstandard term is divided into two or more modules, the minimum loan period for a Direct Loan is'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 70, '_id': '9f30542e64344a66b5ee9e93976c031c', '_collection_name': 'loan_knowledge_index'}, page_content='credit-hour program.) The loan period will be for the first full academic year of the new program (the period\\nduring which the student will be expected to complete 24 semester hours and 30 weeks of instructional time).')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"What is the loan repayment period?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Node\n",
        "\n",
        "We're finally ready to create our node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "05qhncktIwK_"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Node\n",
        "\n",
        "Next, let's create our `generate` node - which will leverage LangChain and something called an \"LCEL Chain\" which you can read more about [here](https://python.langchain.com/docs/concepts/lcel/)!\n",
        "\n",
        "We'll want to create a chain that does the following: \n",
        "\n",
        "1. Formats our inputs into a chat template suitable for RAG\n",
        "2. Takes that chat template and sends it to an LLM\n",
        "3. Parses that output into `str` format\n",
        "\n",
        "Let's get chaining!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: RAG Chat Template\n",
        "\n",
        "We'll create a chat template that takes in some query and formats it as a RAG prompt using LangChain's prompt template!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#CONTEXT:\\nOUR CONTEXT HERE\\n\\nQUERY:\\nOUR QUERY HERE\\n\\nUse the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it\\'s not contained in the provided context response with \"I don\\'t know\"\\n'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt.invoke({\"context\" : \"OUR CONTEXT HERE\", \"query\" : \"OUR QUERY HERE\"}).messages[0].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Chain Components: Generator\n",
        "\n",
        "We'll next set-up the generator - which will be OpenAI's `gpt-4o-nano` for today!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now call our model with a formatted prompt.\n",
        "\n",
        "Notice that we have some nested calls here - we'll see that this is made easier by LCEL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 72, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BqpcYj507ILYjl9L6SfCLunbEGp6H', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0b8a08d-2121-4e3d-98df-1fc92cfb0845-0', usage_metadata={'input_tokens': 72, 'output_tokens': 7, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_chat_model.invoke(chat_prompt.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: `str` Parser\n",
        "\n",
        "Finally, let's set-up our `StrOutputParser()` which will transform our model's output into a simple `str` to be provided to the user.\n",
        "\n",
        "> NOTE: You can see us leveraging LCEL in the example below to avoid needing to do nested calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The capital of France is Paris.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "\n",
        "generator_chain.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `generate` Node: \n",
        "\n",
        "Now we can create our `generate` Node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XiL2isC8JS0l"
      },
      "outputs": [],
      "source": [
        "def generate(state: State) -> State:\n",
        "  generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtriMEcJxeR"
      },
      "source": [
        "Now we can start defining our graph!\n",
        "\n",
        "Think of the graph's state as a blank canvas that we can add nodes and edges to.\n",
        "\n",
        "Every graph starts with two special nodes - START and END - the act as the entry and exit point to the other nodes in the graphs.  \n",
        "\n",
        "All valid graphs must start at the START node and end at the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ia9IWM9AJ4bx"
      },
      "outputs": [],
      "source": [
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kro8bQEL2Yj"
      },
      "source": [
        "Now we can add a sequence to our \"canvas\" (graph) - this can be done by providing a list of nodes, the will automatically have edges that connect the i-th element to the i+1-th element in the list. The final element will be added to the END node unless otherwise specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OSfDMlXUL2kh"
      },
      "outputs": [],
      "source": [
        "graph_builder = graph_builder.add_sequence([retrieve, generate])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g79NZf5VL4en"
      },
      "source": [
        "Next, let's connect our START node to our `retrieve` node by adding an edge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w1kTJKGNL4qA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x15dcbbf80>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"retrieve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiVyt8-L6_5"
      },
      "source": [
        "Finally we can compile our graph! This will do basic verification to ensure that the Runnables have the correct inputs/outputs and can be matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TM4My6geL7FW"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvoQcfCP3xI"
      },
      "source": [
        "Finally, we can visualize our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x15de0c5c0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRCjvvyP8DA"
      },
      "source": [
        "Let's take it for a spin!\n",
        "\n",
        "We invoke our graph like we do any other Runnable in LCEL!\n",
        "\n",
        "> NOTE: That's right, even a compiled graph is a Runnable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mSbsRLurKOKd",
        "outputId": "114185f3-4b98-4c66-96cd-65f4e4e3ef1d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Applying for and securing a student loan in 2025 is not necessarily a terrible idea based on the provided context. The documents describe managing loan eligibility, increasing loan amounts when a student's grade level changes during an academic year, and the importance of counseling and adherence to deadlines. They also emphasize that students can plan for their aid, including understanding their loan limits, repayment, and other resources. While there are considerations such as loan limits, eligibility, and counseling requirements, these do not inherently make taking out a student loan in 2025 a bad idea. It largely depends on the individual circumstances and how well the student manages their loans and academic progress."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "response = graph.invoke({\"question\" : \"Is applying for and securing a student loan in 2025 a terrible idea?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_jEmE_rKwED",
        "outputId": "c5fac807-2a24-4cf9-8cca-105def13e3d8"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, the amount of loan money you can receive from the government depends on your enrollment status, program length, and your year in school. There are caps and limits in place:\n",
              "\n",
              "- For a dependent first-year undergraduate enrolling in a 900 clock-hour program, the maximum annual combined loan limit (subsidized and unsubsidized) is $5,500, with no more than $3,500 of that being subsidized. The actual disbursement amounts are typically split into two equal payments.\n",
              "\n",
              "- If your program duration is shorter, the loan limits are prorated based on the hours or weeks completed. For example, a program of fewer hours (like 400 hours in 26 weeks) might limit you to a proportionally smaller loan amount. One example shows that for a 400-hour, 12-week program, the prorated limit could be approximately $2,420.\n",
              "\n",
              "- The total loan amount you can borrow also has an aggregate cap over time, such as $31,000 for dependent undergraduates (excluding certain parent PLUS loans), and higher limits for independent undergraduates and graduate students.\n",
              "\n",
              "In summary, there is a cap on the annual loan amount, which varies based on your program, year, and enrollment status, and there are also lifetime aggregate limits. The specific amount you can get is determined by prorating these limits if your program is shorter than a full academic year."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"How much loan money can I actually get from the government to go to school these days? Is there a cap?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, grants and scholarships that are available for free include Pell Grants, FSEOG (Federal Supplemental Educational Opportunity Grants), and other scholarships that do not require future employment or repayment. Specifically, Pell Grants and FSEOG are mentioned as forms of financial assistance that do not need to be repaid."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"What grants and scholarships are available for free?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I don't know"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"Who is Batman?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LRYXvvRjOp"
      },
      "source": [
        "#### ❓ Question #2:\n",
        "LangGraph's graph-based approach lets us visualize and manage complex flows naturally. How could we extend our current implementation to handle edge cases? For example:\n",
        "- What if the retriever finds no relevant context?  \n",
        "- What if the response needs fact-checking?\n",
        "Consider how you would modify the graph to handle these scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "LangGraph allows you to define if/else statements, and create more graph paths. We can extend the graph to support the scenarios mentioned above, and implement similarity thresholds to avoid retrieving document without relevance to the answer.\n",
        "1. If the retrieval does not get back relevant context the agent should return that it does not the answer.\n",
        "2. If the response needs fact checking we can reflect upon the answer given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_context(state: State) -> State:\n",
        "  if state[\"context\"] is None or len(state[\"context\"]) == 0:\n",
        "    return False\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def no_answer(state: State) -> State:\n",
        "  return {\"response\": \"I don't know man, I'm just a bot.\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5, \"score_threshold\": 0.5})\n",
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "FACT_CHECKING_PROMPT = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "RESPONSE:\n",
        "{response}\n",
        "\n",
        "Use the provide context to fact check the response to the query. Only use the provided context to fact check the response to the query. \n",
        "\"\"\"\n",
        "\n",
        "fact_checking_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", FACT_CHECKING_PROMPT)\n",
        "])\n",
        "\n",
        "def fact_check(state: State) -> State:\n",
        "  generator_chain = fact_checking_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\n",
        "    \"query\" : state[\"question\"], \n",
        "    \"context\" : state[\"context\"],\n",
        "    \"response\" : state[\"response\"]\n",
        "    })\n",
        "  return {\"response\" : response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x15de0d040>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Start with the blank canvas\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder.add_node(\"no_answer\", no_answer)\n",
        "graph_builder.add_node(\"fact_check\", fact_check)\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    verify_context,\n",
        "    {True: \"generate\", False: \"no_answer\"},\n",
        ")\n",
        "graph_builder.add_edge(\"generate\", \"fact_check\")\n",
        "graph_builder.add_edge(\"fact_check\", END)\n",
        "graph_builder.add_edge(\"no_answer\", END)\n",
        "graph = graph_builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I don't know man, I'm just a bot."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"Who is Batman?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
