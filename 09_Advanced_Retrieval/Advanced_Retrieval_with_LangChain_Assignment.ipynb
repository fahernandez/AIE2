{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - 09 - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import EvaluationDataset\n",
        "\n",
        "from ragas.metrics import (\n",
        "    LLMContextRecall,\n",
        "    Faithfulness,\n",
        "    FactualCorrectness,\n",
        "    ResponseRelevancy,\n",
        "    ContextEntityRecall,\n",
        "    NoiseSensitivity,\n",
        ")\n",
        "from ragas import evaluate, RunConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "B25 + semantic search in quadrant fussion has delivered consistent results for Allan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\", \n",
        "      \"Product\", \n",
        "      \"Sub-product\", \n",
        "      \"Issue\", \n",
        "      \"Sub-issue\", \n",
        "      \"Consumer complaint narrative\", \n",
        "      \"Company public response\", \n",
        "      \"Company\", \n",
        "      \"State\", \n",
        "      \"ZIP code\", \n",
        "      \"Tags\", \n",
        "      \"Consumer consent provided?\", \n",
        "      \"Submitted via\", \n",
        "      \"Date sent to company\", \n",
        "      \"Company response to consumer\", \n",
        "      \"Timely response?\", \n",
        "      \"Consumer disputed?\", \n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "825"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]\n",
        "len(loan_complaint_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issues with loans, based on the complaints provided, appear to be related to mismanagement and errors in servicing. This includes incorrect information on credit reports, problems applying payments properly (such as payments being misapplied to interest rather than principal), lack of transparency or communication from servicers, illegal or unfair practices like unauthorized transfers, and discrepancies in loan balances and interest calculations. Many complainants also face difficulties in resolving issues or obtaining accurate loan information, which can lead to financial hardship and credit damage.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, there are several complaints indicating that issues were not handled in a timely manner. Specifically:\\n\\n- One complaint (row 441) from a consumer who reported that their loan application status had no movement and multiple unreturned calls, with delays exceeding the expected response time, and the complaint was categorized as \"Timely response? No.\"\\n- Multiple complaints from Maximus Federal Services, Inc. (rows 67, 400, 816), where consumers reported delays of over a year, nearly 18 months, or several weeks without resolution, often with the company responding \"Closed with explanation\" or with no response. These indicate delays beyond reasonable or expected timeframes.\\n- A complaint (row 816) explicitly states that no resolution has been reached after nearly 18 months, which is an excessively long delay.\\n- Several other complaints mention prolonged waiting times (e.g., over 10 days, several days, or multiple months), and some complaints explicitly state that the response was delayed or the issues were not addressed within a reasonable timeframe.\\n\\nTherefore, yes, several complaints in this data indicate that issues were not handled in a timely manner.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for several reasons, including:\\n\\n1. **Accumulation of interest and repayment challenges:** Many borrowers found that choosing options like forbearance or deferment allowed interest to continue accruing, which increased the total amount owed over time and made repayment more difficult. For example, some reported that even after years of payments, their balances remained high due to ongoing interest.\\n\\n2. **Financial hardships and employment issues:** Borrowers faced financial hardships, including unemployment, stagnating wages, or unexpected expenses, making it impossible to afford repayment or increasing their reliance on forbearance, which can lead to higher accruing interest.\\n\\n3. **Lack of clear communication and mismanagement:** Several complaints highlighted a lack of proper notification about loan transfers, repayment start dates, or delinquency statuses. Some borrowers weren't informed when payments had resumed or when their loans were transferred without their knowledge, leading to missed payments and credit reporting issues.\\n\\n4. **Inability to qualify for forgiveness programs:** Many borrowers did not qualify for loan forgiveness programs like PSLF or TLF, which contributed to prolonged, unmanageable debt.\\n\\n5. **Problems with payment application and servicer practices:** Some reported that their additional payments were not applied to the principal and most went toward interest, prolonging the repayment period and increasing total debt.\\n\\n6. **Administrative errors and technical issues:** Complaints included errors such as incorrect reporting of late payments, failure to notify about delinquencies, or mishandling of account information, which negatively impacted credit scores and repayment ability.\\n\\nOverall, a combination of high interest, insufficient income, lack of transparent communication, and administrative issues contributed to people struggling to repay their loans.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common issue with student loans appears to be problems related to dealing with lenders or servicers, such as miscommunication, incorrect information, or unfair repayment practices. Specific sub-issues include disputes over fees charged, difficulty applying payments correctly, obtaining accurate loan information, and receiving bad or confusing information about loans.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all the complaints mentioned in the context were responded to by the companies and closed with explanation, indicating that they addressed the complaints in a timely manner. Specifically, the responses were marked as \"Yes\" for timely response for each complaint. \\n\\nTherefore, no complaints in the provided context appear to have gone unhandled or unresolved within an appropriate timeframe.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, including miscommunication and administrative errors by loan servicers, inability to get proper assistance or responses when facing repayment difficulties, and issues related to incorrect or outdated information about their loan status. For example, some borrowers experienced their automatic payments being unenrolled without their knowledge, leading to missed payments and negative impacts on their credit scores. Others were improperly steered into the wrong payment plans or forbearances, or did not receive critical notices about their loans or repayment statuses. Additionally, some borrowers reported being unable to get assistance despite repeated efforts, and in certain cases, loan servicers transferred or sold their loans without proper notification, making it difficult for borrowers to keep track or resolve issues. All these factors contributed to difficulties in fulfilling repayment obligations.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### âœ… Answer\n",
        "An example query where BM25 outperforms embeddings is when the user is searching for an exact phrase (names, locations, etc) or specific terminology that appears verbatim in the documents, especially if the phrase is rare.\n",
        "\n",
        "**Example Query:**  \n",
        "*\"What is the difference between 'deferment' and 'forbearance' in student loans?\"*\n",
        "\n",
        "**Justification:**  \n",
        "BM25 is a term-based retrieval method that excels at matching exact keywords and phrases. If a document contains the exact terms \"deferment\" and \"forbearance\" in the context of student loans, BM25 will rank it highly because it directly matches the query terms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, a common issue with loans appears to be problems related to the handling and management of the loans by servicers. This includes errors or discrepancies in loan balances, misapplied payments, wrongful denials of payment plans, incorrect or incomplete information, unauthorized transfers of loans, and poor communication or lack of transparency. Specifically, many complaints highlight issues such as receiving bad or incomplete information about the loan, discrepancies in account balances and interest, and mishandling of personal and loan data, sometimes involving violations of privacy laws like FERPA.\\n\\nIn summary, the most common issue with loans, especially federal student loans in these complaints, involves mishandling and miscommunication by loan servicers, leading to errors in account information, billing, and personal data privacy concerns.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, there are examples indicating that some issues took a significant amount of time to be addressed. For instance, one complaint mentions that it has been nearly 18 months with no resolution, and another indicates that an issue has been pending for over one year without response. The complaint about federal student loan servicing related to the account review and account adjustments has also been open for over a year.\\n\\nWhile the responses from the companies in some cases are marked as \"Timely response? Yes,\" the lengthy durations mentioned by complainants suggest that some complaints did not get handled in a timely manner. Therefore, yes, there are complaints that did not get handled promptly.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a lack of clear communication, misunderstanding of their repayment obligations, and the growing burden of interest. Many borrowers were not informed by their financial aid officers that repayment was required, leading to confusion about their responsibilities. Additionally, issues such as incorrect account information, unnotified loan transfers, and difficulties accessing accurate online data hindered their ability to manage payments properly. \\n\\nFurthermore, even when payment plans were established, the accumulation of interestâ€”especially when loans were put into forbearance or defermentâ€”made it difficult to reduce the principal amount. Borrowers also faced financial hardships, such as stagnant wages and inability to increase monthly payments without compromising basic necessities, which extended the repayment period and increased the total amount owed. Overall, inadequate information, miscommunication, and economic constraints contributed significantly to their failure to fully repay their loans.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints and data, appears to be mismanagement by loan servicers, including errors in loan balances, misapplication of payments, inaccurate or deceptive information, and failure to communicate properly with borrowers. Many complaints involve incorrect account statuses, unintended default classifications, inaccurate reporting on credit reports, and mishandling of deferments or forbearances. Additionally, a significant number of complaints highlight difficulties in obtaining clear, accurate information about loan terms and balances, often compounded by procedural disorganization and lack of transparency from service providers.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, it appears that several complaints did not get handled in a timely manner. For example:\\n\\n- One complaint (Complaint #12739706) regarding an unprocessed graduated loan application was not responded to within the expected timeframe (it was noted as not timely).\\n- Another complaint (Complaint #12709087) about issues with a student loan application was also not addressed promptly, with the complainant indicating that the issue remained unresolved after multiple follow-ups.\\n- Additionally, multiple complaints mention delays of several days to weeks before receiving responses, and some complaints report that the issues persist without resolution.\\n\\nTherefore, yes, many complaints listed did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans primarily due to issues such as lack of clear information about repayment options, mismanagement by loan servicers, high interest accumulation, and miscommunication. Many borrowers were steered into forbearance or consolidation without being informed about the consequences, such as interest capitalization and loss of forgiveness eligibility. Additionally, some faced difficulty understanding when and how to make payments, leading to delinquency and negative impacts on their credit scores. Systemic practices like forbearance steering and inadequate communication by servicers contributed significantly to borrowers' inability to repay their loans successfully.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### âœ… Answer\n",
        "When building a chatbot-like product, it is difficult to anticipate every possible user intent or the exact way users will phrase their questions. Users may ask ambiguous or incomplete questions, or use terminology that differs from the language in your documents. By generating multiple reformulations of a user query, you increase the chances that at least one version will closely match the relevant information in your data. This approach helps surface more relevant documents that might otherwise be missed, thereby improving recall and ensuring the system retrieves a broader and more accurate set of results for the user's true intent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans appears to be related to errors, misconduct, and systemic breakdowns in servicing and reporting. Specifically, common problems involve incorrect information on credit reports, disputes over loan balances and interest rates, misapplication of payments, wrongful denial of payment plans, and issues stemming from loan transfers and sale of loans which lead to confusion and unverified debt reporting. These issues reflect systemic flaws in the loan servicing process, leading to financial and credit reporting problems for borrowers.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, multiple complaints were marked as \"No\" for timely response, indicating that some complaints did not get handled in a timely manner. Specifically, the complaints with Complaint IDs 12709087 and 12935889 both received responses marked as \"No\" for timely response. Therefore, yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People often fail to pay back their loans due to a variety of reasons highlighted in the complaints. Some common causes include:\\n\\n1. **Lack of clear communication and proper notification:** Borrowers reported not being properly informed about payment obligations, due dates, or changes in their loan management, which led to missed payments.\\n\\n2. **Financial hardship and inability to afford payments:** Many borrowers experienced severe financial difficulties, including unemployment or underemployment, making it difficult to keep up with repayment.\\n\\n3. **Misrepresentation and lack of transparency from schools and lenders:** Several borrowers cited misleading information about the value of their education, career prospects, and the debt's manageability, which contributed to their inability to repay.\\n\\n4. **Problems with loan servicing and administrative issues:** Complaints indicate issues like failed or delayed notifications, buying out of loans without notice, and difficulties in establishing payment plans, which hindered timely repayment.\\n\\n5. **Long-term financial consequences and accumulated interest:** Borrowers relying on deferment or forbearance saw their interest grow, increasing their debt burden and making repayment more challenging.\\n\\nThese factors collectively contribute to why many people fail to repay their loans.\""
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, the most common issues with loans, particularly student loans, involve:\\n\\n- Errors in loan balances and misapplied payments\\n- Receiving incorrect or bad information about loans\\n- Difficulty dealing with lenders or servicers, including refusal to apply additional payments to principal, wrongful denials of repayment plans, or problematic payment handling\\n- Problems with loan classification and mismanagement, such as incorrect loan type designation or ending in-school deferments improperly\\n- Discrepancies and inaccuracies in credit reporting, including incorrect late payments, account status errors, or missing payment history\\n- Challenges in obtaining accurate loan information or validation, and issues related to loan transfers and data mishandling\\n- Problems with debt validation, fraud concerns, or improper collection practices\\n- Difficulties with loan forgiveness, cancellation, or discharge applications\\n\\nIn summary, the most common issue appears to be *mismanagement and inaccuracies in loan handling and information*, which include errors in balances, misapplication of payments, incorrect reporting, and poor communication with lenders or servicers.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints data, yes, some complaints were not handled in a timely manner. For example:\\n\\n- Complaint ID 12935889 about a Mohela account was marked as \"No\" for timely response.\\n- Complaint ID 12654977 about a student loan payment not being applied was also marked as \"No\" for timely response.\\n- Complaint ID 12744910 regarding payments showing late was marked \"Yes,\" indicating it was handled timely.\\n- Complaint ID 13056764 about inaccurate credit reporting was handled timely (\"Yes\").\\n- Complaint ID 12823876 about delayed follow-up and unrecorded payments was handled timely (\"Yes\").\\n\\nAdditionally, some complaints explicitly state delays or unresponsiveness, such as complaint ID 12935889 and 13056764, which show that complaints did not get addressed promptly. Therefore, there are instances indicating that some complaints were not handled in a timely manner.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a combination of factors highlighted in the complaints:\\n\\n1. **Lack of Clear Information and Communication:** Many borrowers were not properly informed about their repayment obligations, when payments were due, or the status of their payments. Instances include unnotified loan transfers, failure to receive notices about delinquency, and lack of confirmation when payments were made.\\n\\n2. **Technical and Administrative Errors:** Complaints include payments being reversed without explanation, inaccurate reporting of delinquency or late payments, and difficulties in applying payments correctly, often leading to errors in loan balances and credit reports.\\n\\n3. **High and Growing Interest Due to Mismanagement:** Several borrowers mentioned that interest continues to accrue and capitalize, especially during forbearance or deferment periods, causing their debt to grow over time despite making payments.\\n\\n4. **Inadequate Support for Hardship or Payment Difficulties:** Borrowers seeking helpâ€”such as deferments, income-driven plans, or guidanceâ€”often received insufficient or no assistance, or were steered into forbearance and other options that extended repayment duration, increasing total debt.\\n\\n5. **Misleading or Deceptive Practices:** Complaints of loan servicers re-routing payments, misapplying funds, or failing to notify borrowers about critical changes and options, which resulted in unintentional missed payments or delinquency.\\n\\n6. **Systemic Errors and Data Discrepancies:** Inconsistent reporting, failure to update loan status properly, and errors in credit reporting caused additional hardships, making repayment more difficult.\\n\\n7. **Economic Hardship and Unforeseen Circumstances:** Many borrowers encountered financial hardship, job loss, or underestimated the impact of accruing interest, which made payments unmanageable despite their willingness and efforts to pay.\\n\\nIn summary, a combination of poor communication, administrative errors, interest accumulation, systemic mismanagement, and insufficient support for borrowers resulted in many individuals being unable to repay their loans effectively.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints data, the most common issues with loans tend to revolve around miscommunication, errors, or delays in servicing, including problems with payment handling, inaccurate reporting, or lack of transparency. However, the issues that stand out most frequently involve problems with repayment processes, such as incorrect payment amounts, failure to update loan status, or poor communication from loan servicers.\\n\\nTherefore, the most common issue appears to be **problems related to loan servicing and payment handling**, particularly errors in billing, delays, and lack of clear communication.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, it appears that many complaints were responded to in a timely manner, with responses marked as \\'Yes\\' under the \\'Timely response?\\' field. Notably, several complaints state \"Closed with explanation,\" indicating that they were addressed within the required time frame. \\n\\nHowever, there is at least one complaint regarding a lack of response or handlingâ€”specifically, the complaint about Nelnet (row 17). The consumer\\'s narrative details multiple issues with lack of responses and conduct that suggests their complaint was not handled promptly or satisfactorily.\\n\\nIn summary:\\n\\n- Multiple complaints confirm responses were handled in a timely manner.\\n- One complaint (about Nelnet\\'s failure to respond to Certified Mail and ongoing misconduct) indicates that the complaint was not properly handled or responded to, suggesting that some complaints did not get handled in a timely manner.\\n\\nTherefore, yes, some complaints did not get handled in a timely manner, specifically the complaint involving Nelnet\\'s lack of response to legal and misconduct issues.'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for various reasons, including issues such as difficulties dealing with their loan servicers, miscommunications or inadequate information about their loan status, problems with payment processing, and disputes over the legitimacy or accuracy of their loan details. Some specific reasons noted in the complaints include receiving bad information about loan statuses, delays or errors in re-amortizing payments after forbearance ended, and inaccurate reports of default or delinquency. Additionally, instances of alleged mismanagement, lack of transparency, or improper handling of personal data have also contributed to borrowers' difficulties in repayment.\""
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If sentences are short and highly repetitive the chunking algorithm could produce many nearly identical or overlapping chunks, leading to redundancy in the vector store and making it harder for the retriever to distinguish between different questions or answers. \n",
        "\n",
        "To address this, we can increase the chunk size by combining multiple short sentences or QA pairs, deduplicate content to remove or merge highly similar chunks, and attach metadata like question IDs or categories to help disambiguate similar content. Additionally, implementing custom chunking logicâ€”such as grouping by topic or intentâ€”can ensure each chunk represents a unique theme, while adjusting embedding granularity or experimenting with different embedding models can help capture subtle differences and improve retrieval quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 0, relationships: 0)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 20, relationships: 0)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
        "for doc in loan_complaint_data[:20]:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\n",
        "                \"page_content\": doc.page_content,\n",
        "                \"document_metadata\": doc.metadata,\n",
        "            },\n",
        "        )\n",
        "    )\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "495fd1a881d14eb780bca4122ac011bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ef44900300448f5898a1879ffe2146d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node ca64b5a2-9ae6-4437-aa5b-96654d11c859 does not have a summary. Skipping filtering.\n",
            "Node c1c8b805-4f50-495e-9f36-067ca21ef5cb does not have a summary. Skipping filtering.\n",
            "Node 21e3179c-5337-484d-b15c-c76deda51f93 does not have a summary. Skipping filtering.\n",
            "Node c9ec7062-a6e1-49f1-9ed9-72abf17f9a99 does not have a summary. Skipping filtering.\n",
            "Node b814c8cf-ef19-4fe5-beb7-1c2d9e0b2106 does not have a summary. Skipping filtering.\n",
            "Node 3e61f1bf-d07a-4673-83e1-c90466a271a6 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd96d69c48814fc19e390131d85f4081",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf2878cd9c3d4414a2454d7736eaabe0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 19, relationships: 19)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import default_transforms, apply_transforms\n",
        "\n",
        "transformer_llm = generator_llm\n",
        "embedding_model = generator_embeddings\n",
        "\n",
        "default_transforms = default_transforms(\n",
        "    documents=loan_complaint_data, llm=transformer_llm, embedding_model=embedding_model\n",
        ")\n",
        "apply_transforms(kg, default_transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 19, relationships: 19)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"loan_data_kg.json\")\n",
        "loan_data_kg = KnowledgeGraph.load(\"loan_data_kg.json\")\n",
        "loan_data_kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(\n",
        "    llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loan_data_kg\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import (\n",
        "    default_query_distribution,\n",
        "    SingleHopSpecificQuerySynthesizer\n",
        ")\n",
        "\n",
        "query_distribution = [\n",
        "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71350f5ce7a5466c83989f39a428fcbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a4c63cd2d974d58a331a81618dcf385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did the end of the COVID-19 forbearance pr...</td>\n",
              "      <td>[The federal student loan COVID-19 forbearance...</td>\n",
              "      <td>The federal student loan COVID-19 forbearance ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How is Aidvantage handling borrower complaints...</td>\n",
              "      <td>[I submitted my annual Income-Driven Repayment...</td>\n",
              "      <td>The context describes a borrower who submitted...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does FERPA protect student data and what a...</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>My personal and financial data was compromised...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does the Fair Credit Reporting Act ensure ...</td>\n",
              "      <td>[I am writing to formally dispute inaccurate i...</td>\n",
              "      <td>The Fair Credit Reporting Act (FCRA), specific...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>As a Privacy and Consumer Rights Advocate, how...</td>\n",
              "      <td>[I am devastated. I would like to report a sit...</td>\n",
              "      <td>The individual reports that they have never be...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What role did the Department of Government Eff...</td>\n",
              "      <td>[On XXXX XXXX XXXX, XXXX XXXX instructed his t...</td>\n",
              "      <td>On XXXX XXXX XXXX, XXXX XXXX instructed his te...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the issue with the EdFinancial forms ...</td>\n",
              "      <td>[I have provided documentation relating to my ...</td>\n",
              "      <td>Our Human Resources department provided separa...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does FERPA protect student data privacy?</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>My personal and financial data was compromised...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the violation of the Higer Education ...</td>\n",
              "      <td>[I am writing to formally dispute my XXXX XXXX...</td>\n",
              "      <td>The violation of the Higher Education Act demo...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does HIPAA relate to the violations of rig...</td>\n",
              "      <td>[Breach of Contract - All four branches have v...</td>\n",
              "      <td>In the context provided, HIPAA is listed among...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  How did the end of the COVID-19 forbearance pr...   \n",
              "1  How is Aidvantage handling borrower complaints...   \n",
              "2  How does FERPA protect student data and what a...   \n",
              "3  How does the Fair Credit Reporting Act ensure ...   \n",
              "4  As a Privacy and Consumer Rights Advocate, how...   \n",
              "5  What role did the Department of Government Eff...   \n",
              "6  How does the issue with the EdFinancial forms ...   \n",
              "7       How does FERPA protect student data privacy?   \n",
              "8  How does the violation of the Higer Education ...   \n",
              "9  How does HIPAA relate to the violations of rig...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [The federal student loan COVID-19 forbearance...   \n",
              "1  [I submitted my annual Income-Driven Repayment...   \n",
              "2  [My personal and financial data was compromise...   \n",
              "3  [I am writing to formally dispute inaccurate i...   \n",
              "4  [I am devastated. I would like to report a sit...   \n",
              "5  [On XXXX XXXX XXXX, XXXX XXXX instructed his t...   \n",
              "6  [I have provided documentation relating to my ...   \n",
              "7  [My personal and financial data was compromise...   \n",
              "8  [I am writing to formally dispute my XXXX XXXX...   \n",
              "9  [Breach of Contract - All four branches have v...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  The federal student loan COVID-19 forbearance ...   \n",
              "1  The context describes a borrower who submitted...   \n",
              "2  My personal and financial data was compromised...   \n",
              "3  The Fair Credit Reporting Act (FCRA), specific...   \n",
              "4  The individual reports that they have never be...   \n",
              "5  On XXXX XXXX XXXX, XXXX XXXX instructed his te...   \n",
              "6  Our Human Resources department provided separa...   \n",
              "7  My personal and financial data was compromised...   \n",
              "8  The violation of the Higher Education Act demo...   \n",
              "9  In the context provided, HIPAA is listed among...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  single_hop_specifc_query_synthesizer  \n",
              "5  single_hop_specifc_query_synthesizer  \n",
              "6  single_hop_specifc_query_synthesizer  \n",
              "7  single_hop_specifc_query_synthesizer  \n",
              "8  single_hop_specifc_query_synthesizer  \n",
              "9  single_hop_specifc_query_synthesizer  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Naive Retrieval Evaluation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "naive_retrieval_dataset = testset.to_pandas().copy()\n",
        "naive_retrieval_dataset[\"response\"] = \"\"\n",
        "naive_retrieval_dataset[\"retrieved_contexts\"] = [[] for _ in range(len(pd_dataset))]\n",
        "\n",
        "for k, v in naive_retrieval_dataset.iterrows():\n",
        "    response = naive_retrieval_chain.invoke({\"question\": v.user_input})\n",
        "    naive_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
        "    naive_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
        "        context.page_content for context in response[\"context\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "603b6162c2bd47f6aa6415637654fd75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[38]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[40]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.9750, 'faithfulness': 0.7829, 'factual_correctness': 0.4800, 'answer_relevancy': 0.8567, 'context_entity_recall': 0.6016, 'noise_sensitivity_relevant': 0.4199}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_result = evaluate(\n",
        "    dataset=EvaluationDataset.from_pandas(naive_retrieval_dataset),\n",
        "    metrics=[\n",
        "        LLMContextRecall(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        ResponseRelevancy(),\n",
        "        ContextEntityRecall(),\n",
        "        NoiseSensitivity(),\n",
        "    ],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=RunConfig(timeout=360),\n",
        ")\n",
        "naive_retrieval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bm25 Retrieval Evaluation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_retrieval_dataset = testset.to_pandas().copy()\n",
        "bm25_retrieval_dataset[\"response\"] = \"\"\n",
        "bm25_retrieval_dataset[\"retrieved_contexts\"] = [[] for _ in range(len(pd_dataset))]\n",
        "\n",
        "for k, v in bm25_retrieval_dataset.iterrows():\n",
        "    response = bm25_retrieval_chain.invoke({\"question\": v.user_input})\n",
        "    bm25_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
        "    bm25_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
        "        context.page_content for context in response[\"context\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "622cfe8a6f9b4b7f9425d5992f7c7b6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[47]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[40]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.7750, 'faithfulness': 0.7864, 'factual_correctness': 0.4670, 'answer_relevancy': 0.9745, 'context_entity_recall': 0.4984, 'noise_sensitivity_relevant': 0.3671}"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_result = evaluate(\n",
        "    dataset=EvaluationDataset.from_pandas(bm25_retrieval_dataset),\n",
        "    metrics=[\n",
        "        LLMContextRecall(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        ResponseRelevancy(),\n",
        "        ContextEntityRecall(),\n",
        "        NoiseSensitivity(),\n",
        "    ],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=RunConfig(timeout=360),\n",
        ")\n",
        "bm25_retrieval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contextual Compression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_compression_retrieval_dataset = testset.to_pandas().copy()\n",
        "context_compression_retrieval_dataset[\"response\"] = \"\"\n",
        "context_compression_retrieval_dataset[\"retrieved_contexts\"] = [[] for _ in range(len(pd_dataset))]\n",
        "\n",
        "for k, v in context_compression_retrieval_dataset.iterrows():\n",
        "    response = contextual_compression_retrieval_chain.invoke({\"question\": v.user_input})\n",
        "    context_compression_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
        "    context_compression_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
        "        context.page_content for context in response[\"context\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fbc960f92144bf9a7c03cdecac37090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[44]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[38]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[47]: AttributeError('StringIO' object has no attribute 'statements')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8250, 'faithfulness': 0.7676, 'factual_correctness': 0.4475, 'answer_relevancy': 0.8689, 'context_entity_recall': 0.5248, 'noise_sensitivity_relevant': 0.3479}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_compression_retrieval_result = evaluate(\n",
        "    dataset=EvaluationDataset.from_pandas(context_compression_retrieval_dataset),\n",
        "    metrics=[\n",
        "        LLMContextRecall(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        ResponseRelevancy(),\n",
        "        ContextEntityRecall(),\n",
        "        NoiseSensitivity(),\n",
        "    ],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=RunConfig(timeout=360),\n",
        ")\n",
        "context_compression_retrieval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-query retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_query_retrieval_dataset = testset.to_pandas().copy()\n",
        "multi_query_retrieval_dataset[\"response\"] = \"\"\n",
        "multi_query_retrieval_dataset[\"retrieved_contexts\"] = [\n",
        "    [] for _ in range(len(pd_dataset))\n",
        "]\n",
        "\n",
        "for k, v in multi_query_retrieval_dataset.iterrows():\n",
        "    response = multi_query_retrieval_chain.invoke({\"question\": v.user_input})\n",
        "    multi_query_retrieval_dataset.at[k, \"response\"] = response[\n",
        "        \"response\"\n",
        "    ].content\n",
        "    multi_query_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
        "        context.page_content for context in response[\"context\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11cd31972a264112b31cf32e127862f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[8]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[11]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[10]: TimeoutError()\n",
            "Exception raised in Job[23]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[40]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.9750, 'faithfulness': 0.8394, 'factual_correctness': 0.4678, 'answer_relevancy': 0.8692, 'context_entity_recall': 0.6042, 'noise_sensitivity_relevant': 0.4617}"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_result = evaluate(\n",
        "    dataset=EvaluationDataset.from_pandas(multi_query_retrieval_dataset),\n",
        "    metrics=[\n",
        "        LLMContextRecall(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        ResponseRelevancy(),\n",
        "        ContextEntityRecall(),\n",
        "        NoiseSensitivity(),\n",
        "    ],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=RunConfig(timeout=360),\n",
        ")\n",
        "multi_query_retrieval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Retrieval Method             | Context Recall | Faithfulness | Factual Correctness | Answer Relevancy | Context Entity Recall | Noise Sensitivity Relevant |\n",
        "|-----------------------------|:--------------:|:------------:|:-------------------:|:----------------:|:---------------------:|:--------------------------:|\n",
        "| **Naive Retrieval**         | 0.9750         | 0.7829       | 0.4800              | 0.8567           | 0.6016                | 0.4199                     |\n",
        "| **BM25 Retrieval**          | 0.7750         | 0.7864       | 0.4670              | 0.9745           | 0.4984                | 0.3671                     |\n",
        "| **Context Compression**     | 0.8250         | 0.7676       | 0.4475              | 0.8689           | 0.5248                | 0.3479                     |\n",
        "| **Multi-Query Retrieval**   | 0.9750         | 0.8394       | 0.4678              | 0.8692           | 0.6042                | 0.4617                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Retrieval Method           | Cost per request      | Mean Time (seconds) |\n",
        "|---------------------------|-------------------|----------------|\n",
        "| Naive Retrieval           | $0.00034036       | 3.17           |\n",
        "| BM25 Retrieval            | $0.00049501       | 3.63           |\n",
        "| Context Compression       | $0.00031641       | 5.30           |\n",
        "| Multi-Query Retrieval     | $0.00114227       | 6.44  |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
